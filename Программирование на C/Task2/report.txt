*************************
10 English texts united in "data" (88635 lines)

1: Used time for frequence dictionary by standard utilites (result -> dict_std.txt):
	  real 2.37
	  user 0.00
	  sys  0.00

2: Used time for frequence dictionary by own utilites (linesort merge, result -> dict.txt): 
	  real 1.01
	  user 0.00
	  sys  0.00

3: Used time for frequence dictionary by hash table (result -> dict_hash.txt):
	  real 0.75
	  user 0.00
	  sys  0.00
*************************
1 English text in "data" (5395 lines)

1: Used time for frequence dictionary by standard utilites (result -> dict_std.txt):
	  real 0.01
	  user 0.00
	  sys  0.00

2: Used time for frequence dictionary by own utilites (linesort merge, result -> dict.txt): 
	  real 0.07
	  user 0.00
	  sys  0.00

3: Used time for frequence dictionary by hash table (result -> dict_hash.txt):
	  real 0.07
	  user 0.00
	  sys  0.00
*************************
Conclusion: 
> the results show that merge sort and hash table work more 
effective with file consisting of 88635 lines than standard utilites.
> the results show that standard utilites work more 
effective with file consisting of 5395 lines than merge sort and hash table.
